---
title: "5.3.1 为什么这一节很重要"
order: 3
---

# 5.3.1 为什么这一节很重要

## 真实案例：10 分钟损失数千美元

这是 2024-2025 年间反复发生的场景：

1. 开发者用 AI 生成代码
2. AI 把 API 密钥直接写进了代码里
3. 代码被上传到 GitHub（即使是私有仓库也不安全）
4. **几分钟后，账户被盗刷**

2024 年 11 月，区块链项目 Pump Science 就因为 GitHub 密钥泄露，导致攻击者创建了欺诈性代币，造成用户损失。

## 大规模凭证盗窃事件

2024 年 10 月，安全研究人员发现了代号为 **EMERALDWHALE** 的攻击行动：

- 攻击者扫描了约 **5 亿个 IP 地址**
- 从暴露的 Git 配置文件中窃取了超过 **15,000 个云服务凭证**
- 涉及 **10,000+ 个私有代码仓库**
- 被盗凭证被用于钓鱼攻击和垃圾邮件

这些凭证包括 AWS 密钥、数据库连接字符串、API Token——都是开发者"不小心"提交到代码库里的。

## 为什么 AI 编程时代风险更高

还记得第三章提到的 AI 幻觉吗？在安全领域，AI 的"不靠谱"可能直接导致：

| AI 行为 | 安全后果 |
|---------|---------|
| 把密钥当作"示例"写进代码 | 密钥泄露 |
| 推荐不存在的软件包 | 可能安装恶意代码 |
| 跳过输入验证 | 留下安全漏洞 |
| 使用过时的加密方式 | 数据容易被破解 |

根据 Veracode 2025 报告，当 AI 在"安全写法"和"不安全写法"之间做选择时，**45% 的情况下会选择不安全的方式**。

## 好消息

**只要知道规则，就能轻松避免。**

接下来的几节会教你：
- 什么是绝对不能做的（三大禁令）
- 如何检查代码中的安全隐患
- 如何识别 AI 推荐的可疑软件包
- 如何养成安全审查习惯

这些知识会让你比 90% 的初学者更安全。

→ [5.3.2 绝对禁区：永远不要告诉 AI](./5.3.2-never-tell-ai.md)
