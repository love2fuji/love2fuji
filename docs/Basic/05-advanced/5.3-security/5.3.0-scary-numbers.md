---
title: "5.3.0 2025年安全现状：触目惊心的数字"
order: 2
---

# 5.3.0 2025年安全现状：触目惊心的数字

> 这些不是危言耸听，而是 2024-2025 年权威机构发布的真实数据。

经过本节学习，你将了解：
- AI 生成代码的安全风险有多普遍
- 密钥泄露问题有多严重
- 为什么现在就要重视安全

## AI 生成代码的安全风险

来源：Veracode 2025 GenAI Code Security Report

Veracode 在 2025 年测试了超过 100 个大语言模型，分析它们生成的 Java、Python、JavaScript、C# 代码。结果令人担忧：

| 数据 | 含义 |
|------|------|
| **45%** | AI 生成的代码未通过安全测试 |
| **72%** | Java 代码的安全失败率（所有语言中最高） |
| **86%** | AI 未能防御跨站脚本攻击的比例 |
| **88%** | AI 未能防御日志注入攻击的比例 |

更值得注意的是：**更新、更大的模型并没有产生更安全的代码**。安全性能在过去几年几乎没有改善。

## 密钥泄露危机

来源：GitHub 2025、GitGuardian 2025、Verizon DBIR 2025

| 数据 | 来源 | 含义 |
|------|------|------|
| **3900 万** | GitHub 2025 | 2024 年在 GitHub 上检测到的泄露密钥数量 |
| **2380 万** | GitGuardian 2025 | 2024 年公开仓库新增的泄露凭证（同比增长 25%） |
| **70%** | GitGuardian 2025 | 2022 年泄露的密钥至今仍然有效 |
| **35%** | GitGuardian 2025 | 私有仓库包含明文密钥的比例 |
| **94 天** | Verizon DBIR 2025 | 泄露密钥的平均修复时间 |

这意味着：攻击者平均有 **3 个月的时间窗口** 来利用泄露的密钥。

## 顶级公司也难逃一劫

| 数据 | 含义 |
|------|------|
| **65%** | Forbes AI 50 榜单中的顶级 AI 公司曾在 GitHub 上泄露过凭证 |
| **$488 万** | 涉及凭证泄露的数据泄露事件平均成本（IBM 2024） |

如果连这些技术最先进的公司都会犯错，普通开发者更需要警惕。

## 新兴威胁：包幻觉攻击

来源：德克萨斯大学、俄克拉荷马大学、弗吉尼亚理工联合研究（2025）

| 数据 | 含义 |
|------|------|
| **19.7%** | AI 推荐的软件包实际上不存在 |
| **21.7%** | 开源模型的包幻觉率 |
| **5.2%** | GPT 系列模型的包幻觉率（相对较低） |
| **58%** | 幻觉包名会重复出现，可被攻击者预测 |

攻击者已经开始利用这个漏洞：注册 AI 常"幻觉"出来的包名，植入恶意代码，等待开发者上钩。

## 这些数字意味着什么

::: warning 核心信息
这些数字不是为了吓你，而是告诉你一个事实：

**AI 编程的安全风险是真实存在的，不是"以后再说"的事情。**

但好消息是：只要了解规则，大部分风险都可以轻松避免。
:::

接下来的几节会告诉你具体怎么做。

→ [5.3.1 为什么这一节很重要](./5.3.1-why-important.md)
