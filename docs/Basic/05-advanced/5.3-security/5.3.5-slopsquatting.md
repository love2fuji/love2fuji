---
title: "5.3.5 AI 推荐的库安全吗（Slopsquatting）"
order: 7
---

# 5.3.5 AI 推荐的库安全吗？

经过本节学习，你将了解：
- 什么是 Slopsquatting 攻击
- 为什么 AI 推荐的库可能有风险
- 如何验证一个库是否安全
- 真实的恶意包案例

## 还记得 AI 幻觉吗？

在第三章，我们讨论过 AI 有时会"一本正经地胡说八道"——给出看起来合理但实际上错误的回答。

在安全领域，这种"幻觉"会造成严重后果。

**AI 可能会推荐根本不存在的软件包。**

根据德克萨斯大学等研究机构 2025 年的研究：
- **19.7%** 的 AI 推荐的包实际上不存在
- 开源模型的幻觉率高达 **21.7%**
- 即使是 GPT 系列，也有 **5.2%** 的幻觉率
- **58%** 的幻觉包名会重复出现，可被预测

## 什么是 Slopsquatting？

**Slopsquatting** 是 2024-2025 年出现的新型攻击方式，名字来源于：
- **Slop**：指 AI 生成的"废话"或错误内容
- **Squatting**：抢注（就像域名抢注一样）

**攻击原理**：

```
1. 攻击者研究 AI 常"幻觉"出的包名
   （比如 AI 经常推荐一个叫 "aws-helper-sdk" 的包，但它不存在）

2. 攻击者抢先注册这个包名
   （在 npm 或 PyPI 上创建一个真实的 "aws-helper-sdk" 包）

3. 在包中植入恶意代码
   （比如窃取环境变量、下载后门程序）

4. 等待开发者上钩
   （开发者信任 AI 推荐，直接安装）

5. 恶意代码被执行
   （开发者的密钥、数据被盗取）
```

## 真实案例

### 案例一：aiocpa 恶意包（2024年11月）

Python 库 **aiocpa**（一个加密货币支付 API 客户端）被发现：
- 在 0.1.13 版本中植入了恶意代码
- 会将用户的 **Crypto Pay API Token** 通过 Telegram Bot 发送给攻击者
- 该包在被发现前已被下载超过 **12,000 次**

### 案例二：solana-systemprogram-utils（2024年12月）

npm 上发现的恶意包：
- 伪装成 Solana 区块链的工具库
- 会在 **2% 的交易中**，悄悄将资金转到攻击者地址
- 因为比例低，很难被立即发现

### 案例三：GitHub Actions 供应链攻击（2025年9月）

代号 **GhostAction** 的攻击：
- 利用 AI 编程工具生成的 GitHub Actions 配置
- 从 **817 个仓库**中窃取凭证
- 受影响的开发者超过 **5,500 人**

## 如何保护自己

### 步骤一：验证包是否存在

安装任何 AI 推荐的包之前，先去官方网站确认：

| 语言 | 官方包仓库 | 网址 |
|------|-----------|------|
| JavaScript/Node.js | npm | npmjs.com |
| Python | PyPI | pypi.org |
| Go | Go Packages | pkg.go.dev |
| Rust | crates.io | crates.io |

### 步骤二：检查包的可信度

在官方仓库中搜索到包后，检查：

| 指标 | 安全信号 | 警惕信号 |
|------|---------|---------|
| 下载量 | 周下载量较高（数千以上） | 下载量很低（几十或更少） |
| 维护状态 | 最近有更新 | 超过 2 年没更新 |
| 作者 | 知名组织或有多个项目 | 只有这一个包，无其他活动 |
| 依赖者 | 被其他流行项目使用 | 没有其他项目依赖 |
| 仓库 | 有关联的 GitHub 仓库 | 没有源码仓库 |

### 步骤三：警惕"新发现"的包

如果 AI 推荐了一个你从未听过的包：

```
✅ 先在搜索引擎中搜索这个包名
✅ 看看是否有人在技术论坛或博客中讨论过
✅ 检查是否有官方文档
✅ 如果找不到任何信息，很可能是幻觉
```

### 步骤四：仔细阅读 AI 的推荐

有时候 AI 会给出这样的建议：

```javascript
// AI 可能会说：
// "你可以使用 super-easy-auth 库来处理认证"
npm install super-easy-auth
```

**在执行安装命令之前**，先问自己：
- 这个库我听过吗？
- 去 npmjs.com 搜索存在吗？
- 下载量怎么样？

## 开源模型 vs 商业模型

研究表明，不同模型的幻觉率差异很大：

| 模型类型 | 幻觉率 | 说明 |
|---------|--------|------|
| 开源模型（如 CodeLlama） | ~21.7% | 每 5 个推荐中可能有 1 个是假的 |
| GPT 系列 | ~5.2% | 相对较低，但仍需警惕 |

**无论使用哪个模型，都应该验证。**

## 记住这个原则

::: warning 核心原则
**AI 推荐的包 ≠ 存在的包 ≠ 安全的包**

在安装任何新依赖之前，花 30 秒去官方仓库验证，可以避免很多麻烦。
:::

→ [5.3.6 永远审查代码](./5.3.6-always-review.md)
