import{_ as E,C as d,c as A,o as t,a3 as e,b as l,w as o,a as n,G as i,a4 as r}from"./chunks/framework.CUcrqFol.js";const D=JSON.parse('{"title":"12.2.1 搜索引擎如何工作——搜索引擎优化基础：爬虫与索引原理","description":"12.2.1 搜索引擎如何工作——搜索引擎优化基础：爬虫与索引原理 一句话破题 搜索引擎通过\\"爬虫\\"抓取网页、\\"索引\\"整理内容、\\"排名\\"决定展示顺序——理解这三步，就掌握了 SEO 优化的底层逻辑。 本质还原：搜索引擎的工作流程 爬取阶段 搜索引擎的\\"爬虫\\"（如 Googlebot、Baiduspider）是一个自动化","frontmatter":{"title":"12.2.1 搜索引擎如何工作——搜索引擎优化基础：爬虫与索引原理","typora-root-url":"../../public"},"headers":[],"relativePath":"Advanced-old/12-advanced/12.2-seo/12.2.1-crawlers.md","filePath":"Advanced-old/12-advanced/12.2-seo/12.2.1-crawlers.md","lastUpdated":1766168364000}'),p={name:"Advanced-old/12-advanced/12.2-seo/12.2.1-crawlers.md"};function c(B,a,u,h,g,_){const s=d("Mermaid");return t(),A("div",null,[a[2]||(a[2]=e('<h1 id="_12-2-1-搜索引擎如何工作——搜索引擎优化基础-爬虫与索引原理" tabindex="-1">12.2.1 搜索引擎如何工作——搜索引擎优化基础：爬虫与索引原理 <a class="header-anchor" href="#_12-2-1-搜索引擎如何工作——搜索引擎优化基础-爬虫与索引原理" aria-label="Permalink to &quot;12.2.1 搜索引擎如何工作——搜索引擎优化基础：爬虫与索引原理&quot;">​</a></h1><h3 id="一句话破题" tabindex="-1">一句话破题 <a class="header-anchor" href="#一句话破题" aria-label="Permalink to &quot;一句话破题&quot;">​</a></h3><p>搜索引擎通过&quot;爬虫&quot;抓取网页、&quot;索引&quot;整理内容、&quot;排名&quot;决定展示顺序——理解这三步，就掌握了 SEO 优化的底层逻辑。</p><h3 id="本质还原-搜索引擎的工作流程" tabindex="-1">本质还原：搜索引擎的工作流程 <a class="header-anchor" href="#本质还原-搜索引擎的工作流程" aria-label="Permalink to &quot;本质还原：搜索引擎的工作流程&quot;">​</a></h3>',4)),(t(),l(r,null,{default:o(()=>[i(s,{id:"mermaid-12",class:"mermaid",graph:"flowchart%20LR%0A%20%20%20%20A%5B%22%E7%88%AC%E5%8F%96%20Crawling%22%5D%20--%3E%20B%5B%22%E7%B4%A2%E5%BC%95%20Indexing%22%5D%0A%20%20%20%20B%20--%3E%20C%5B%22%E6%8E%92%E5%90%8D%20Ranking%22%5D%0A%20%20%20%20C%20--%3E%20D%5B%22%E5%B1%95%E7%A4%BA%20Serving%22%5D%0A%20%20%20%20%0A%20%20%20%20A1%5B%22%E7%88%AC%E8%99%AB%E8%AE%BF%E9%97%AE%E7%BD%91%E9%A1%B5%22%5D%20--%3E%20A%0A%20%20%20%20B1%5B%22%E5%88%86%E6%9E%90%E9%A1%B5%E9%9D%A2%E5%86%85%E5%AE%B9%22%5D%20--%3E%20B%0A%20%20%20%20C1%5B%22%E7%AE%97%E6%B3%95%E8%AF%84%E4%BC%B0%E7%9B%B8%E5%85%B3%E6%80%A7%22%5D%20--%3E%20C%0A%20%20%20%20D1%5B%22%E8%BF%94%E5%9B%9E%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C%22%5D%20--%3E%20D%0A"})]),fallback:o(()=>[...a[0]||(a[0]=[n(" Loading... ",-1)])]),_:1})),a[3]||(a[3]=e('<h4 id="_1-爬取阶段" tabindex="-1">1. 爬取阶段 <a class="header-anchor" href="#_1-爬取阶段" aria-label="Permalink to &quot;1. 爬取阶段&quot;">​</a></h4><p>搜索引擎的&quot;爬虫&quot;（如 Googlebot、Baiduspider）是一个自动化程序，它会：</p><ol><li>从已知页面的链接出发，发现新页面</li><li>请求页面的 HTML 内容</li><li>解析 HTML，提取文本、链接、图片等信息</li><li>将发现的新链接加入待爬取队列</li></ol><p><strong>关键点</strong>：</p><ul><li>爬虫主要看的是 <strong>HTML 源码</strong>，而不是渲染后的页面</li><li>现代爬虫（如 Googlebot）可以执行 JavaScript，但有延迟和限制</li><li>爬虫会遵守 <code>robots.txt</code> 的规则</li></ul><h4 id="_2-索引阶段" tabindex="-1">2. 索引阶段 <a class="header-anchor" href="#_2-索引阶段" aria-label="Permalink to &quot;2. 索引阶段&quot;">​</a></h4><p>爬取到的内容会被处理并存入&quot;索引库&quot;：</p><ul><li><strong>内容分析</strong>：提取关键词、识别页面主题</li><li><strong>去重处理</strong>：识别并过滤重复内容</li><li><strong>质量评估</strong>：判断页面的权威性、原创性</li><li><strong>关系建立</strong>：理解页面之间的链接关系</li></ul><h4 id="_3-排名阶段" tabindex="-1">3. 排名阶段 <a class="header-anchor" href="#_3-排名阶段" aria-label="Permalink to &quot;3. 排名阶段&quot;">​</a></h4><p>当用户搜索时，搜索引擎会从索引库中找出相关页面，并根据数百个因素进行排名：</p><ul><li><strong>内容相关性</strong>：页面内容与搜索词的匹配程度</li><li><strong>页面质量</strong>：内容的深度、原创性、更新频率</li><li><strong>用户体验</strong>：加载速度、移动端适配、交互体验</li><li><strong>外部信号</strong>：其他网站的链接（外链）、社交分享</li></ul><h3 id="爬虫眼中的你的网页" tabindex="-1">爬虫眼中的你的网页 <a class="header-anchor" href="#爬虫眼中的你的网页" aria-label="Permalink to &quot;爬虫眼中的你的网页&quot;">​</a></h3>',12)),(t(),l(r,null,{default:o(()=>[i(s,{id:"mermaid-120",class:"mermaid",graph:"graph%20TD%0A%20%20%20%20subgraph%20%22%E7%88%AC%E8%99%AB%E8%83%BD%E7%9C%8B%E5%88%B0%22%0A%20%20%20%20%20%20%20%20A%5B%22HTML%20%E6%BA%90%E7%A0%81%22%5D%0A%20%20%20%20%20%20%20%20B%5B%22%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%B8%B2%E6%9F%93%E5%86%85%E5%AE%B9%22%5D%0A%20%20%20%20%20%20%20%20C%5B%22Meta%20%E6%A0%87%E7%AD%BE%22%5D%0A%20%20%20%20%20%20%20%20D%5B%22%E7%BB%93%E6%9E%84%E5%8C%96%E6%95%B0%E6%8D%AE%22%5D%0A%20%20%20%20%20%20%20%20E%5B%22%E9%93%BE%E6%8E%A5%E7%BB%93%E6%9E%84%22%5D%0A%20%20%20%20end%0A%20%20%20%20%0A%20%20%20%20subgraph%20%22%E7%88%AC%E8%99%AB%E7%9C%8B%E4%B8%8D%E5%88%B0%E6%88%96%E6%9C%89%E5%9B%B0%E9%9A%BE%22%0A%20%20%20%20%20%20%20%20F%5B%22%E9%9C%80%E8%A6%81%E7%99%BB%E5%BD%95%E7%9A%84%E5%86%85%E5%AE%B9%22%5D%0A%20%20%20%20%20%20%20%20G%5B%22JavaScript%20%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD%E5%86%85%E5%AE%B9%22%5D%0A%20%20%20%20%20%20%20%20H%5B%22Flash%2FCanvas%20%E5%86%85%E5%AE%B9%22%5D%0A%20%20%20%20%20%20%20%20I%5B%22%E8%A2%AB%20robots.txt%20%E7%A6%81%E6%AD%A2%E7%9A%84%E9%A1%B5%E9%9D%A2%22%5D%0A%20%20%20%20end%0A"})]),fallback:o(()=>[...a[1]||(a[1]=[n(" Loading... ",-1)])]),_:1})),a[4]||(a[4]=e(`<h3 id="robots-txt-与爬虫的-君子协定" tabindex="-1">robots.txt：与爬虫的&quot;君子协定&quot; <a class="header-anchor" href="#robots-txt-与爬虫的-君子协定" aria-label="Permalink to &quot;robots.txt：与爬虫的&quot;君子协定&quot;&quot;">​</a></h3><p><code>robots.txt</code> 是放在网站根目录的文件，用于告诉爬虫哪些内容可以抓取：</p><div class="language-txt vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">txt</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span># 允许所有爬虫访问所有内容</span></span>
<span class="line"><span>User-agent: *</span></span>
<span class="line"><span>Allow: /</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 禁止爬虫访问管理后台</span></span>
<span class="line"><span>Disallow: /admin/</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 指定站点地图位置</span></span>
<span class="line"><span>Sitemap: https://example.com/sitemap.xml</span></span></code></pre></div><h3 id="ai-协作指南" tabindex="-1">AI 协作指南 <a class="header-anchor" href="#ai-协作指南" aria-label="Permalink to &quot;AI 协作指南&quot;">​</a></h3><ul><li><strong>核心意图</strong>：让 AI 帮你生成 <code>robots.txt</code> 或检查现有配置是否合理。</li><li><strong>需求定义公式</strong>：<code>&quot;请帮我生成一个 robots.txt 文件，允许搜索引擎抓取所有公开页面，但禁止抓取 /api/ 和 /admin/ 目录。&quot;</code></li><li><strong>关键术语</strong>：<code>robots.txt</code>、<code>User-agent</code>、<code>Disallow</code>、<code>Sitemap</code>、<code>noindex</code></li></ul><h3 id="避坑指南" tabindex="-1">避坑指南 <a class="header-anchor" href="#避坑指南" aria-label="Permalink to &quot;避坑指南&quot;">​</a></h3><ul><li><strong>不要屏蔽 CSS 和 JS</strong>：现代爬虫需要这些资源来正确渲染页面。</li><li><strong>注意 noindex 和 Disallow 的区别</strong>：<code>Disallow</code> 阻止爬取，<code>noindex</code> 阻止索引。被 Disallow 的页面如果有外链指向，仍可能被索引。</li><li><strong>定期检查爬取状态</strong>：使用 Google Search Console 或百度站长工具监控爬虫行为。</li></ul>`,7))])}const m=E(p,[["render",c]]);export{D as __pageData,m as default};
